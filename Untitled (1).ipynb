{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c90b1050",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "\n",
    "# Загрузка и предварительная обработка данных\n",
    "data = pd.read_csv('basketball.csv')\n",
    "\n",
    "\n",
    "# Вычисление общего счета игры\n",
    "data['totalScore'] = (\n",
    "    data['firstQuarterAwayScore'] + data['secondQuarterAwayScore'] + \n",
    "    data['thirdQuarterAwayScore'] + data['fourthQuarterAwayScore'] + \n",
    "    data['firstQuarterHomeScore'] + data['secondQuarterHomeScore'] + \n",
    "    data['thirdQuarterHomeScore'] + data['fourthQuarterHomeScore']\n",
    ")\n",
    "\n",
    "# Вычисление среднего счета для каждой команды\n",
    "average_score_away = data.groupby('awayTeam')['awayScore'].mean()\n",
    "average_score_home = data.groupby('homeTeam')['homeScore'].mean()\n",
    "\n",
    "data['averageScoreAway'] = data['awayTeam'].map(average_score_away)\n",
    "data['averageScoreHome'] = data['homeTeam'].map(average_score_home)\n",
    "\n",
    "# Кодирование названий команд\n",
    "encoder = OneHotEncoder(sparse=False)\n",
    "team_names = data[['awayTeam', 'homeTeam']]\n",
    "encoded_teams = encoder.fit_transform(team_names)\n",
    "\n",
    "# Добавление закодированных данных обратно в исходный DataFrame\n",
    "encoded_team_names = pd.DataFrame(encoded_teams, columns=encoder.get_feature_names_out(team_names.columns))\n",
    "data_encoded = pd.concat([data.reset_index(drop=True), encoded_team_names], axis=1)\n",
    "\n",
    "# Подготовка данных для обучения модели\n",
    "features = data_encoded[encoded_team_names.columns.tolist() + ['averageScoreAway', 'averageScoreHome']]\n",
    "target = data_encoded['totalScore']\n",
    "\n",
    "# Разделение на обучающий и тестовый наборы\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=42)\n",
    "\n",
    "# Масштабирование данных\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Создание модели нейронной сети\n",
    "model_nn = Sequential()\n",
    "model_nn.add(Dense(64, input_dim=X_train_scaled.shape[1], activation='relu'))\n",
    "model_nn.add(Dense(32, activation='relu'))\n",
    "model_nn.add(Dense(1))  # Один выходной нейрон без функции активации для регрессии\n",
    "\n",
    "# Компиляция модели\n",
    "model_nn.compile(optimizer=Adam(learning_rate=0.001), loss='mean_squared_error')\n",
    "\n",
    "# Обучение модели\n",
    "model_nn.fit(X_train_scaled, y_train, epochs=100, batch_size=10, verbose=1)\n",
    "\n",
    "# Оценка модели\n",
    "loss = model.evaluate(X_test_scaled, y_test)\n",
    "print(f\"Loss (Mean Squared Error): {loss}\")\n",
    "\n",
    "# Прогнозирование с помощью модели\n",
    "y_pred = model_nn.predict(X_test_scaled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "798411f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5450ee22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Данные для прогнозирования\n",
    "teams_for_prediction = pd.DataFrame({\n",
    "    'awayTeam': ['Phoenix Suns (Hayley)'],\n",
    "    'homeTeam': ['Dallas Mavericks (Maisie)']\n",
    "})\n",
    "\n",
    "\n",
    "# Преобразование названий команд в one-hot encoding\n",
    "encoded_teams_for_prediction = encoder.transform(teams_for_prediction[['awayTeam', 'homeTeam']])\n",
    "\n",
    "# Создание DataFrame для one-hot encoded данных\n",
    "encoded_teams_for_prediction_df = pd.DataFrame(encoded_teams_for_prediction, columns=encoder.get_feature_names_out())\n",
    "\n",
    "# Получение средних значений для команд из teams_for_prediction\n",
    "average_away = average_score_away.loc[teams_for_prediction['awayTeam'][0]]\n",
    "average_home = average_score_home.loc[teams_for_prediction['homeTeam'][0]]\n",
    "\n",
    "# Убедитесь, что признаки в final_prediction_data совпадают с features\n",
    "final_prediction_data = pd.concat([encoded_teams_for_prediction_df, pd.DataFrame({'averageScoreAway': [average_away], 'averageScoreHome': [average_home]})], axis=1)[features.columns]\n",
    "\n",
    "# Прогнозирование с использованием модели\n",
    "final_prediction_data_scaled = scaler.transform(final_prediction_data)\n",
    "predicted_score = model_nn.predict(final_prediction_data_scaled)\n",
    "print(f\"Прогнозируемый общий счет игры: {predicted_score[0]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c42e89b4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "final_prediction_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "497ac437",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "\n",
    "# Загрузка и предварительная обработка данных\n",
    "data = pd.read_csv('basketball.csv')\n",
    "\n",
    "# Вычисление общего счета игры\n",
    "data['totalScore'] = (\n",
    "    data['firstQuarterAwayScore'] + data['secondQuarterAwayScore'] + \n",
    "    data['thirdQuarterAwayScore'] + data['fourthQuarterAwayScore'] + \n",
    "    data['firstQuarterHomeScore'] + data['secondQuarterHomeScore'] + \n",
    "    data['thirdQuarterHomeScore'] + data['fourthQuarterHomeScore']\n",
    ")\n",
    "\n",
    "# Вычисление среднего счета для каждой команды\n",
    "average_score_away = data.groupby('awayTeam')['awayScore'].mean()\n",
    "average_score_home = data.groupby('homeTeam')['homeScore'].mean()\n",
    "\n",
    "data['averageScoreAway'] = data['awayTeam'].map(average_score_away)\n",
    "data['averageScoreHome'] = data['homeTeam'].map(average_score_home)\n",
    "\n",
    "# Кодирование названий команд\n",
    "encoder = OneHotEncoder(sparse=False)\n",
    "team_names = data[['awayTeam', 'homeTeam']]\n",
    "encoded_teams = encoder.fit_transform(team_names)\n",
    "\n",
    "# Добавление закодированных данных обратно в исходный DataFrame\n",
    "encoded_team_names = pd.DataFrame(encoded_teams, columns=encoder.get_feature_names_out(team_names.columns))\n",
    "data_encoded = pd.concat([data.reset_index(drop=True), encoded_team_names], axis=1)\n",
    "\n",
    "# Подготовка данных для обучения модели\n",
    "features = data_encoded[encoded_team_names.columns.tolist() + ['averageScoreAway', 'averageScoreHome']]\n",
    "target = data_encoded['totalScore']\n",
    "\n",
    "# Разделение на обучающий и тестовый наборы\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=42)\n",
    "\n",
    "# Масштабирование данных\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Преобразование данных в тензоры PyTorch\n",
    "X_train_torch = torch.tensor(X_train_scaled.astype(np.float32))\n",
    "y_train_torch = torch.tensor(y_train.values.astype(np.float32))\n",
    "X_test_torch = torch.tensor(X_test_scaled.astype(np.float32))\n",
    "y_test_torch = torch.tensor(y_test.values.astype(np.float32))\n",
    "\n",
    "# Определение модели\n",
    "class RegressionModel(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(RegressionModel, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 64)\n",
    "        self.fc2 = nn.Linear(64, 32)\n",
    "        self.fc3 = nn.Linear(32, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "# Функции для обучения и оценки модели\n",
    "def train_model(model, criterion, optimizer, X_train, y_train, epochs=1000):\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(X_train)\n",
    "        loss = criterion(outputs.squeeze(), y_train)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "def evaluate_model(model, criterion, X_test, y_test):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        y_pred = model(X_test)\n",
    "        loss = criterion(y_pred.squeeze(), y_test)\n",
    "    return loss.item()\n",
    "\n",
    "# Кросс-валидация\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "fold_results = []\n",
    "\n",
    "for train_index, test_index in kf.split(X_train_scaled):\n",
    "    # Разделение данных\n",
    "    X_train_fold = torch.tensor(X_train_scaled[train_index].astype(np.float32))\n",
    "    y_train_fold = torch.tensor(y_train.values[train_index].astype(np.float32))\n",
    "    X_test_fold = torch.tensor(X_train_scaled[test_index].astype(np.float32))\n",
    "    y_test_fold = torch.tensor(y_train.values[test_index].astype(np.float32))\n",
    "    \n",
    "    # Инициализация модели и оптимизатора\n",
    "    model = RegressionModel(X_train_fold.shape[1])\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    criterion = nn.MSELoss()\n",
    "\n",
    "    # Обучение модели\n",
    "    train_model(model, criterion, optimizer, X_train_fold, y_train_fold, epochs=1000)\n",
    "\n",
    "    # Оценка модели\n",
    "    loss = evaluate_model(model, criterion, X_test_fold, y_test_fold)\n",
    "    fold_results.append(loss)\n",
    "\n",
    "# Вывод результатов кросс-валидации\n",
    "print(f\"Средняя ошибка (Mean Squared Error) на кросс-валидации: {np.mean(fold_results)}, Стандартное отклонение: {np.std(fold_results)}\")\n",
    "\n",
    "# Инициализация и обучение финальной модели\n",
    "model_final = RegressionModel(X_train_torch.shape[1])\n",
    "optimizer_final = optim.Adam(model_final.parameters(), lr=0.001)\n",
    "train_model(model_final, criterion, optimizer_final, X_train_torch, y_train_torch, epochs=1000)\n",
    "\n",
    "# Оценка финальной модели\n",
    "final_loss = evaluate_model(model_final, criterion, X_test_torch, y_test_torch)\n",
    "print(f\"Финальная ошибка (Mean Squared Error) на тестовом наборе: {final_loss}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a53c1556",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dominov/anaconda3/lib/python3.11/site-packages/sklearn/preprocessing/_encoders.py:972: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 32188.388671875\n",
      "Epoch 11, Loss: 32069.58984375\n",
      "Epoch 21, Loss: 31887.34765625\n",
      "Epoch 31, Loss: 31527.5078125\n",
      "Epoch 41, Loss: 30848.169921875\n",
      "Epoch 51, Loss: 29674.916015625\n",
      "Epoch 61, Loss: 27834.939453125\n",
      "Epoch 71, Loss: 25206.744140625\n",
      "Epoch 81, Loss: 21775.1015625\n",
      "Epoch 91, Loss: 17656.408203125\n",
      "Epoch 101, Loss: 13110.72265625\n",
      "Epoch 111, Loss: 8563.310546875\n",
      "Epoch 121, Loss: 4638.0458984375\n",
      "Epoch 131, Loss: 2004.0654296875\n",
      "Epoch 141, Loss: 860.38916015625\n",
      "Epoch 151, Loss: 628.3214111328125\n",
      "Epoch 161, Loss: 587.9473876953125\n",
      "Epoch 171, Loss: 534.0349731445312\n",
      "Epoch 181, Loss: 499.8909912109375\n",
      "Epoch 191, Loss: 483.87530517578125\n",
      "Epoch 201, Loss: 471.9736022949219\n",
      "Epoch 211, Loss: 461.5197448730469\n",
      "Epoch 221, Loss: 452.7330017089844\n",
      "Epoch 231, Loss: 445.09136962890625\n",
      "Epoch 241, Loss: 438.1982116699219\n",
      "Epoch 251, Loss: 431.9093017578125\n",
      "Epoch 261, Loss: 426.14202880859375\n",
      "Epoch 271, Loss: 420.8433532714844\n",
      "Epoch 281, Loss: 415.92755126953125\n",
      "Epoch 291, Loss: 411.3482360839844\n",
      "Epoch 301, Loss: 407.0544738769531\n",
      "Epoch 311, Loss: 403.0227355957031\n",
      "Epoch 321, Loss: 399.229736328125\n",
      "Epoch 331, Loss: 395.65704345703125\n",
      "Epoch 341, Loss: 392.2760009765625\n",
      "Epoch 351, Loss: 389.0700378417969\n",
      "Epoch 361, Loss: 386.03070068359375\n",
      "Epoch 371, Loss: 383.1650390625\n",
      "Epoch 381, Loss: 380.4486389160156\n",
      "Epoch 391, Loss: 377.8750915527344\n",
      "Epoch 401, Loss: 375.4328918457031\n",
      "Epoch 411, Loss: 373.1082763671875\n",
      "Epoch 421, Loss: 370.88970947265625\n",
      "Epoch 431, Loss: 368.773681640625\n",
      "Epoch 441, Loss: 366.7516784667969\n",
      "Epoch 451, Loss: 364.8230285644531\n",
      "Epoch 461, Loss: 362.9823913574219\n",
      "Epoch 471, Loss: 361.22039794921875\n",
      "Epoch 481, Loss: 359.5320739746094\n",
      "Epoch 491, Loss: 357.9167175292969\n",
      "Epoch 501, Loss: 356.3610534667969\n",
      "Epoch 511, Loss: 354.8651123046875\n",
      "Epoch 521, Loss: 353.4349670410156\n",
      "Epoch 531, Loss: 352.0660705566406\n",
      "Epoch 541, Loss: 350.7518005371094\n",
      "Epoch 551, Loss: 349.4881591796875\n",
      "Epoch 561, Loss: 348.2712707519531\n",
      "Epoch 571, Loss: 347.10528564453125\n",
      "Epoch 581, Loss: 345.98577880859375\n",
      "Epoch 591, Loss: 344.90826416015625\n",
      "Epoch 601, Loss: 343.86932373046875\n",
      "Epoch 611, Loss: 342.8697814941406\n",
      "Epoch 621, Loss: 341.9063415527344\n",
      "Epoch 631, Loss: 340.9812316894531\n",
      "Epoch 641, Loss: 340.08990478515625\n",
      "Epoch 651, Loss: 339.2300720214844\n",
      "Epoch 661, Loss: 338.39678955078125\n",
      "Epoch 671, Loss: 337.585693359375\n",
      "Epoch 681, Loss: 336.79669189453125\n",
      "Epoch 691, Loss: 336.03289794921875\n",
      "Epoch 701, Loss: 335.29656982421875\n",
      "Epoch 711, Loss: 334.5809020996094\n",
      "Epoch 721, Loss: 333.8852844238281\n",
      "Epoch 731, Loss: 333.2093811035156\n",
      "Epoch 741, Loss: 332.5536193847656\n",
      "Epoch 751, Loss: 331.91558837890625\n",
      "Epoch 761, Loss: 331.295166015625\n",
      "Epoch 771, Loss: 330.6922912597656\n",
      "Epoch 781, Loss: 330.1049499511719\n",
      "Epoch 791, Loss: 329.5347595214844\n",
      "Epoch 801, Loss: 328.9798889160156\n",
      "Epoch 811, Loss: 328.4395751953125\n",
      "Epoch 821, Loss: 327.9160461425781\n",
      "Epoch 831, Loss: 327.4080810546875\n",
      "Epoch 841, Loss: 326.9143371582031\n",
      "Epoch 851, Loss: 326.4319152832031\n",
      "Epoch 861, Loss: 325.9633483886719\n",
      "Epoch 871, Loss: 325.5071716308594\n",
      "Epoch 881, Loss: 325.0621032714844\n",
      "Epoch 891, Loss: 324.62841796875\n",
      "Epoch 901, Loss: 324.2025451660156\n",
      "Epoch 911, Loss: 323.7850036621094\n",
      "Epoch 921, Loss: 323.37890625\n",
      "Epoch 931, Loss: 322.98150634765625\n",
      "Epoch 941, Loss: 322.5924987792969\n",
      "Epoch 951, Loss: 322.21234130859375\n",
      "Epoch 961, Loss: 321.8399658203125\n",
      "Epoch 971, Loss: 321.47674560546875\n",
      "Epoch 981, Loss: 321.1234436035156\n",
      "Epoch 991, Loss: 320.7774963378906\n",
      "Epoch 1001, Loss: 320.4374694824219\n",
      "Epoch 1011, Loss: 320.10467529296875\n",
      "Epoch 1021, Loss: 319.7783508300781\n",
      "Epoch 1031, Loss: 319.4588928222656\n",
      "Epoch 1041, Loss: 319.1458740234375\n",
      "Epoch 1051, Loss: 318.8398742675781\n",
      "Epoch 1061, Loss: 318.5415954589844\n",
      "Epoch 1071, Loss: 318.24993896484375\n",
      "Epoch 1081, Loss: 317.9651794433594\n",
      "Epoch 1091, Loss: 317.6851806640625\n",
      "Epoch 1101, Loss: 317.40960693359375\n",
      "Epoch 1111, Loss: 317.1421203613281\n",
      "Epoch 1121, Loss: 316.88385009765625\n",
      "Epoch 1131, Loss: 316.63189697265625\n",
      "Epoch 1141, Loss: 316.3853759765625\n",
      "Epoch 1151, Loss: 316.1435241699219\n",
      "Epoch 1161, Loss: 315.9064636230469\n",
      "Epoch 1171, Loss: 315.6745300292969\n",
      "Epoch 1181, Loss: 315.446533203125\n",
      "Epoch 1191, Loss: 315.2222900390625\n",
      "Epoch 1201, Loss: 315.0027160644531\n",
      "Epoch 1211, Loss: 314.787841796875\n",
      "Epoch 1221, Loss: 314.5777282714844\n",
      "Epoch 1231, Loss: 314.3720397949219\n",
      "Epoch 1241, Loss: 314.1706848144531\n",
      "Epoch 1251, Loss: 313.9732666015625\n",
      "Epoch 1261, Loss: 313.77972412109375\n",
      "Epoch 1271, Loss: 313.58892822265625\n",
      "Epoch 1281, Loss: 313.3995666503906\n",
      "Epoch 1291, Loss: 313.212158203125\n",
      "Epoch 1301, Loss: 313.02880859375\n",
      "Epoch 1311, Loss: 312.8481140136719\n",
      "Epoch 1321, Loss: 312.6702575683594\n",
      "Epoch 1331, Loss: 312.49517822265625\n",
      "Epoch 1341, Loss: 312.3229675292969\n",
      "Epoch 1351, Loss: 312.1543273925781\n",
      "Epoch 1361, Loss: 311.9880065917969\n",
      "Epoch 1371, Loss: 311.8240051269531\n",
      "Epoch 1381, Loss: 311.6631164550781\n",
      "Epoch 1391, Loss: 311.5056457519531\n",
      "Epoch 1401, Loss: 311.350830078125\n",
      "Epoch 1411, Loss: 311.1966857910156\n",
      "Epoch 1421, Loss: 311.0443115234375\n",
      "Epoch 1431, Loss: 310.8943176269531\n",
      "Epoch 1441, Loss: 310.74908447265625\n",
      "Epoch 1451, Loss: 310.6070251464844\n",
      "Epoch 1461, Loss: 310.4676818847656\n",
      "Epoch 1471, Loss: 310.3298034667969\n",
      "Epoch 1481, Loss: 310.1910705566406\n",
      "Epoch 1491, Loss: 310.0519714355469\n",
      "Epoch 1501, Loss: 309.9161071777344\n",
      "Epoch 1511, Loss: 309.7856140136719\n",
      "Epoch 1521, Loss: 309.6562805175781\n",
      "Epoch 1531, Loss: 309.52825927734375\n",
      "Epoch 1541, Loss: 309.4015197753906\n",
      "Epoch 1551, Loss: 309.2758483886719\n",
      "Epoch 1561, Loss: 309.1532897949219\n",
      "Epoch 1571, Loss: 309.0334777832031\n",
      "Epoch 1581, Loss: 308.91558837890625\n",
      "Epoch 1591, Loss: 308.7998046875\n",
      "Epoch 1601, Loss: 308.6864013671875\n",
      "Epoch 1611, Loss: 308.5744934082031\n",
      "Epoch 1621, Loss: 308.4642639160156\n",
      "Epoch 1631, Loss: 308.355224609375\n",
      "Epoch 1641, Loss: 308.2474060058594\n",
      "Epoch 1651, Loss: 308.1414794921875\n",
      "Epoch 1661, Loss: 308.0372619628906\n",
      "Epoch 1671, Loss: 307.9345703125\n",
      "Epoch 1681, Loss: 307.8331604003906\n",
      "Epoch 1691, Loss: 307.7329406738281\n",
      "Epoch 1701, Loss: 307.6335144042969\n",
      "Epoch 1711, Loss: 307.53509521484375\n",
      "Epoch 1721, Loss: 307.43792724609375\n",
      "Epoch 1731, Loss: 307.3415832519531\n",
      "Epoch 1741, Loss: 307.24615478515625\n",
      "Epoch 1751, Loss: 307.1518859863281\n",
      "Epoch 1761, Loss: 307.0593566894531\n",
      "Epoch 1771, Loss: 306.9681701660156\n",
      "Epoch 1781, Loss: 306.8782958984375\n",
      "Epoch 1791, Loss: 306.7891540527344\n",
      "Epoch 1801, Loss: 306.7008056640625\n",
      "Epoch 1811, Loss: 306.6129455566406\n",
      "Epoch 1821, Loss: 306.5260314941406\n",
      "Epoch 1831, Loss: 306.44012451171875\n",
      "Epoch 1841, Loss: 306.3552551269531\n",
      "Epoch 1851, Loss: 306.27154541015625\n",
      "Epoch 1861, Loss: 306.1889953613281\n",
      "Epoch 1871, Loss: 306.1077575683594\n",
      "Epoch 1881, Loss: 306.02764892578125\n",
      "Epoch 1891, Loss: 305.9486083984375\n",
      "Epoch 1901, Loss: 305.8705749511719\n",
      "Epoch 1911, Loss: 305.7933044433594\n",
      "Epoch 1921, Loss: 305.7164306640625\n",
      "Epoch 1931, Loss: 305.6398010253906\n",
      "Epoch 1941, Loss: 305.5635681152344\n",
      "Epoch 1951, Loss: 305.4881591796875\n",
      "Epoch 1961, Loss: 305.4134521484375\n",
      "Epoch 1971, Loss: 305.33929443359375\n",
      "Epoch 1981, Loss: 305.26556396484375\n",
      "Epoch 1991, Loss: 305.1925964355469\n",
      "Epoch 2001, Loss: 305.1206359863281\n",
      "Epoch 2011, Loss: 305.0495300292969\n",
      "Epoch 2021, Loss: 304.97918701171875\n",
      "Epoch 2031, Loss: 304.91033935546875\n",
      "Epoch 2041, Loss: 304.84234619140625\n",
      "Epoch 2051, Loss: 304.77496337890625\n",
      "Epoch 2061, Loss: 304.70855712890625\n",
      "Epoch 2071, Loss: 304.6427917480469\n",
      "Epoch 2081, Loss: 304.5786437988281\n",
      "Epoch 2091, Loss: 304.515625\n",
      "Epoch 2101, Loss: 304.4533386230469\n",
      "Epoch 2111, Loss: 304.391845703125\n",
      "Epoch 2121, Loss: 304.33099365234375\n",
      "Epoch 2131, Loss: 304.27117919921875\n",
      "Epoch 2141, Loss: 304.2120666503906\n",
      "Epoch 2151, Loss: 304.1532897949219\n",
      "Epoch 2161, Loss: 304.0950012207031\n",
      "Epoch 2171, Loss: 304.0372314453125\n",
      "Epoch 2181, Loss: 303.98004150390625\n",
      "Epoch 2191, Loss: 303.92364501953125\n",
      "Epoch 2201, Loss: 303.8680114746094\n",
      "Epoch 2211, Loss: 303.8130187988281\n",
      "Epoch 2221, Loss: 303.7586669921875\n",
      "Epoch 2231, Loss: 303.7046813964844\n",
      "Epoch 2241, Loss: 303.6515197753906\n",
      "Epoch 2251, Loss: 303.5989990234375\n",
      "Epoch 2261, Loss: 303.5467834472656\n",
      "Epoch 2271, Loss: 303.49456787109375\n",
      "Epoch 2281, Loss: 303.4429626464844\n",
      "Epoch 2291, Loss: 303.3918762207031\n",
      "Epoch 2301, Loss: 303.3412780761719\n",
      "Epoch 2311, Loss: 303.2912902832031\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2321, Loss: 303.2418518066406\n",
      "Epoch 2331, Loss: 303.1927795410156\n",
      "Epoch 2341, Loss: 303.144287109375\n",
      "Epoch 2351, Loss: 303.09478759765625\n",
      "Epoch 2361, Loss: 303.0454406738281\n",
      "Epoch 2371, Loss: 302.996826171875\n",
      "Epoch 2381, Loss: 302.9488830566406\n",
      "Epoch 2391, Loss: 302.90185546875\n",
      "Epoch 2401, Loss: 302.85516357421875\n",
      "Epoch 2411, Loss: 302.8089599609375\n",
      "Epoch 2421, Loss: 302.76409912109375\n",
      "Epoch 2431, Loss: 302.7196044921875\n",
      "Epoch 2441, Loss: 302.6757507324219\n",
      "Epoch 2451, Loss: 302.6328430175781\n",
      "Epoch 2461, Loss: 302.5906066894531\n",
      "Epoch 2471, Loss: 302.54888916015625\n",
      "Epoch 2481, Loss: 302.5074462890625\n",
      "Epoch 2491, Loss: 302.4664001464844\n",
      "Epoch 2501, Loss: 302.4254455566406\n",
      "Epoch 2511, Loss: 302.38482666015625\n",
      "Epoch 2521, Loss: 302.3443908691406\n",
      "Epoch 2531, Loss: 302.3042907714844\n",
      "Epoch 2541, Loss: 302.2644958496094\n",
      "Epoch 2551, Loss: 302.2244567871094\n",
      "Epoch 2561, Loss: 302.18450927734375\n",
      "Epoch 2571, Loss: 302.1452331542969\n",
      "Epoch 2581, Loss: 302.1070251464844\n",
      "Epoch 2591, Loss: 302.0702819824219\n",
      "Epoch 2601, Loss: 302.03387451171875\n",
      "Epoch 2611, Loss: 301.997802734375\n",
      "Epoch 2621, Loss: 301.9618225097656\n",
      "Epoch 2631, Loss: 301.9260559082031\n",
      "Epoch 2641, Loss: 301.8911437988281\n",
      "Epoch 2651, Loss: 301.85650634765625\n",
      "Epoch 2661, Loss: 301.82220458984375\n",
      "Epoch 2671, Loss: 301.7884521484375\n",
      "Epoch 2681, Loss: 301.755126953125\n",
      "Epoch 2691, Loss: 301.722412109375\n",
      "Epoch 2701, Loss: 301.690185546875\n",
      "Epoch 2711, Loss: 301.6582336425781\n",
      "Epoch 2721, Loss: 301.6264953613281\n",
      "Epoch 2731, Loss: 301.59521484375\n",
      "Epoch 2741, Loss: 301.5633850097656\n",
      "Epoch 2751, Loss: 301.5303649902344\n",
      "Epoch 2761, Loss: 301.4982604980469\n",
      "Epoch 2771, Loss: 301.4668273925781\n",
      "Epoch 2781, Loss: 301.4359130859375\n",
      "Epoch 2791, Loss: 301.4055480957031\n",
      "Epoch 2801, Loss: 301.3772888183594\n",
      "Epoch 2811, Loss: 301.3494567871094\n",
      "Epoch 2821, Loss: 301.322021484375\n",
      "Epoch 2831, Loss: 301.2949523925781\n",
      "Epoch 2841, Loss: 301.2680358886719\n",
      "Epoch 2851, Loss: 301.2407531738281\n",
      "Epoch 2861, Loss: 301.2133483886719\n",
      "Epoch 2871, Loss: 301.1862487792969\n",
      "Epoch 2881, Loss: 301.1593017578125\n",
      "Epoch 2891, Loss: 301.1321716308594\n",
      "Epoch 2901, Loss: 301.1060485839844\n",
      "Epoch 2911, Loss: 301.08062744140625\n",
      "Epoch 2921, Loss: 301.05535888671875\n",
      "Epoch 2931, Loss: 301.030517578125\n",
      "Epoch 2941, Loss: 301.0059509277344\n",
      "Epoch 2951, Loss: 300.9815673828125\n",
      "Epoch 2961, Loss: 300.9574890136719\n",
      "Epoch 2971, Loss: 300.93359375\n",
      "Epoch 2981, Loss: 300.9099426269531\n",
      "Epoch 2991, Loss: 300.8866271972656\n",
      "Test Loss (Mean Squared Error): 461.25885009765625\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "\n",
    "# Загрузка и предварительная обработка данных (используем тот же процесс)\n",
    "data = pd.read_csv('basketball.csv')\n",
    "\n",
    "# Вычисление общего счета игры\n",
    "data['totalScore'] = (\n",
    "    data['firstQuarterAwayScore'] + data['secondQuarterAwayScore'] + \n",
    "    data['thirdQuarterAwayScore'] + data['fourthQuarterAwayScore'] + \n",
    "    data['firstQuarterHomeScore'] + data['secondQuarterHomeScore'] + \n",
    "    data['thirdQuarterHomeScore'] + data['fourthQuarterHomeScore']\n",
    ")\n",
    "\n",
    "# Вычисление среднего счета для каждой команды\n",
    "average_score_away = data.groupby('awayTeam')['awayScore'].mean()\n",
    "average_score_home = data.groupby('homeTeam')['homeScore'].mean()\n",
    "\n",
    "data['averageScoreAway'] = data['awayTeam'].map(average_score_away)\n",
    "data['averageScoreHome'] = data['homeTeam'].map(average_score_home)\n",
    "\n",
    "# Кодирование названий команд\n",
    "encoder = OneHotEncoder(sparse=False)\n",
    "team_names = data[['awayTeam', 'homeTeam']]\n",
    "encoded_teams = encoder.fit_transform(team_names)\n",
    "\n",
    "# Добавление закодированных данных обратно в исходный DataFrame\n",
    "encoded_team_names = pd.DataFrame(encoded_teams, columns=encoder.get_feature_names_out(team_names.columns))\n",
    "data_encoded = pd.concat([data.reset_index(drop=True), encoded_team_names], axis=1)\n",
    "\n",
    "# Подготовка данных для обучения модели\n",
    "features = data_encoded[encoded_team_names.columns.tolist() + ['averageScoreAway', 'averageScoreHome']]\n",
    "target = data_encoded['totalScore']\n",
    "\n",
    "# Разделение на обучающий и тестовый наборы\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=42)\n",
    "\n",
    "# Масштабирование данных\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Преобразование данных в тензоры PyTorch\n",
    "X_train_torch = torch.tensor(X_train_scaled.astype(np.float32))\n",
    "y_train_torch = torch.tensor(y_train.values.astype(np.float32))\n",
    "X_test_torch = torch.tensor(X_test_scaled.astype(np.float32))\n",
    "y_test_torch = torch.tensor(y_test.values.astype(np.float32))\n",
    "\n",
    "# Определение модели\n",
    "class RegressionModel(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(RegressionModel, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 64)\n",
    "        self.fc2 = nn.Linear(64, 32)\n",
    "        self.fc3 = nn.Linear(32, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "# Инициализация модели\n",
    "model = RegressionModel(X_train_torch.shape[1])\n",
    "\n",
    "# Определение функции потерь и оптимизатора\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Обучение модели\n",
    "for epoch in range(3000):\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(X_train_torch)\n",
    "    loss = criterion(outputs.squeeze(), y_train_torch)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if epoch % 10 == 0:\n",
    "        print(f'Epoch {epoch+1}, Loss: {loss.item()}')\n",
    "\n",
    "# Оценка модели\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    y_pred = model(X_test_torch)\n",
    "    test_loss = criterion(y_pred.squeeze(), y_test_torch)\n",
    "print(f\"Test Loss (Mean Squared Error): {test_loss.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "45295f3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Прогнозируемый общий счет игры: 186.00289916992188\n"
     ]
    }
   ],
   "source": [
    "# Преобразование данных для прогнозирования в формат, совместимый с моделью\n",
    "teams_for_prediction = pd.DataFrame({\n",
    "    'awayTeam': ['Cleveland Cavaliers (Maisie)'],\n",
    "    'homeTeam': ['Los Angeles Lakers (Lucy)']\n",
    "})\n",
    "\n",
    "# Преобразование названий команд в one-hot encoding\n",
    "encoded_teams_for_prediction = encoder.transform(teams_for_prediction[['awayTeam', 'homeTeam']])\n",
    "\n",
    "# Создание DataFrame для one-hot encoded данных\n",
    "encoded_teams_for_prediction_df = pd.DataFrame(encoded_teams_for_prediction, columns=encoder.get_feature_names_out())\n",
    "\n",
    "# Получение средних значений для команд из teams_for_prediction\n",
    "average_away = average_score_away.loc[teams_for_prediction['awayTeam'][0]]\n",
    "average_home = average_score_home.loc[teams_for_prediction['homeTeam'][0]]\n",
    "\n",
    "# Убедитесь, что признаки в final_prediction_data совпадают с features\n",
    "final_prediction_data = pd.concat([encoded_teams_for_prediction_df, pd.DataFrame({'averageScoreAway': [average_away], 'averageScoreHome': [average_home]})], axis=1)[features.columns]\n",
    "\n",
    "# Масштабирование данных для прогнозирования\n",
    "final_prediction_data_scaled = scaler.transform(final_prediction_data)\n",
    "\n",
    "# Преобразование данных в тензоры PyTorch\n",
    "final_prediction_data_torch = torch.tensor(final_prediction_data_scaled.astype(np.float32))\n",
    "\n",
    "# Предсказание с использованием модели PyTorch\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    predicted_score_torch = model(final_prediction_data_torch)\n",
    "    predicted_score = predicted_score_torch.item()\n",
    "\n",
    "print(f\"Прогнозируемый общий счет игры: {predicted_score}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03fbaee5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
